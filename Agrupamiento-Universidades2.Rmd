
---
title: "Agrupamiento-Universidades"
author: "Brayan Ortiz, Juan Peña, Thalea Hesse, Juan Sebastian Falcon, Daniel Espinal"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(convertr)
library(dplyr)
library(stringr)
library(factoextra)
library(zoo)
library(purrr)
library(Gifi)
library(klaR)
library(clustMixType)
library(reshape2)
library(ggplot2)
library(kableExtra)
```


# Lectura de datos

```{r, echo=FALSE}
datos <- read.csv("datos/CollegeScorecard.csv")
```

# Procesamiento de los datos

El conjunto de datos cuentas con 1725 características, sin embargo muchas de ellas no contienen información. Por esta razón se deciden eliminar las característica que tengan más del 20% en valores NaN. Por otra parte, el conjunto de datos contiene diferentes formas para representar los valores vacíos, por ejemplo cadenas de texto vacías o con espacios y, adicionalmente, hay registros con valores en *PrivacySuppressed*. Todos estos valores se recopilaron y se replazaron por el objeto NA de R.  

Existen variables (INSTNM, NPCURL, INSTURL) con todos los valores, pero no aportan información para el análisis. Estas columnas también fueron eliminadas del conjunto de datos. La variable LOCALE tiene categorías y sub-categorías, por lo cual se decide que no son necesarias ya que con las categorías es suficiente para describir lo que se quiere. Finalmente, se eliminaron variables redudantes del conjunto de datos, por ejemplo, LONGITUDE, LATITUDE, ZIP, entre otras. 


```{r, echo=FALSE}
# Reemplazar algunos valores con NA
df <- replace(datos, datos=="PrivacySuppressed", NA) # revisar: parece que quedan como strings
df <- replace(df, df==" ", NA)
df <- replace(df, df=="", NA)

# Se borran columnas con valores nulos (>20%)
df <- df[,-which(colMeans(is.na(df)) >= 0.2)]

# # Se borran filas con valores nulos
delete.na <- function(df, n=0) {
 df[rowSums(is.na(df)) <= n,]
}
df <- delete.na(df)

# Eliminar columnas manualmente
df <- subset(df, select = -c(INSTNM, NPCURL, INSTURL, UNITID, 
                             OPEID, opeid6))
# Eliminar redundancia
df <- subset(df, select = -c(LATITUDE, LONGITUDE, ZIP, STABBR, st_fips, HBCU, 
                             PBI, ANNHI, TRIBAL, AANAPII, HSI, NANTI, MENONLY, 
                             WOMENONLY))

df$LOCALE <- substr(df$LOCALE,1,1)

```

## Convertir los tipos de datos

Se estandarizan todas las variables categóricas a un mismo tipo de dato: factor. Además, se observa que en gran medida las variables categóricas están dadas por las CIP*, por lo que se decide tenerlas en otro dataframe.  

```{r, echo=FALSE}
columnas <- data.frame(colnames(df))

columnas_CIP <- columnas %>% 
  filter(str_detect(colnames.df., "^CIP"))

df <- df %>% 
  mutate_at(vars(main, region, CONTROL, CURROPER, HCM2, LOCALE, DISTANCEONLY,
                 PREDDEG, HIGHDEG, CURROPER), 
            list(as.factor)) %>% 
  mutate_at(vars(columnas_CIP$colnames.df.), list(as.factor))
```

Por otra parte, se divide el conjunto de datos en variables númericas y categóricas con el fin de facilitar el procesamiento de las componentes principales. Sin embargo, en el conjunto de datos categórico quedaron varias variables numéricas, así que se obtuvo el índice de la última categórica y se extrajeron desde ese índice hasta el final las otra numéricas. Esto luego se unió con el conjunto total de variables numéricas. Las variables CIP* obtenidas previamente se eliminan ya que estas no representan una información fácil de interpretar para cada universidad. 

```{r, echo=FALSE}

#Convertir todos los chr a factor
df <- df %>% mutate(across(.cols=where(is.character), .fns=as.factor))

df_fact <- df[sapply(df, is.factor)] # Acá quedan variables numéricas (RARO xd)

# Obtiene las numéricas que fueron leídas como categóricas
index_i <- grep("CURROPER", colnames(df_fact))+1
index_s <- ncol(df_fact)

df_aux <- df_fact[c(index_i:index_s)]
df_fact <- df_fact[c(0:(index_i-1))]

# en df_aux están las variable numéricas que estaban en df_fact
df_aux <- mutate_all(df_aux, as.numeric)

# Selecciona solo las numéricas
df_num <- df %>% 
    select_if(is.numeric)

# Une los dos datasets numéricos
df_num <- cbind(df_num, df_aux)

# Elimina las variables CIPÖ*
df_fact_nocip <- df_fact[,!(colnames(df_fact) %in% columnas_CIP$colnames.df.)]

#rowSums(is.na(df_fact))
```
 
## Interpolación de los datos faltantes

Los datos numéricos faltantes se completan realizando una extrapolación de los datos que se tienen en la base datos. Se hacen separado para los datos numéricos y enteros. También los datos numéricos se normalizaron con el método Min-Max para dejar los registros en un rango de 0-1.

```{r, echo=FALSE}
# Interpolación para los datos numéricos
df_num <- rapply(df_num, zoo::na.fill,"numeric",fill="extend",how="replace")

# Interpolacińo para los datos enteros
df_num <- rapply(df_num, zoo::na.fill,"integer",fill="extend",how="replace")

# Estandarización de los datos con Min-Max

maxs <- apply(df_num, 2, max)
mins <- apply(df_num, 2, min)

df_num_scale <- scale(df_num, center = mins, scale = maxs - mins)
```

# Componentes principales

Con los datos numéricos extrapolados y estandarizados se hace un análisis de las componente principales. A continuación se presenta este resumen:

```{r, echo=FALSE}
main_pca <- princomp(df_num_scale)
summary(main_pca)
```

De lo anterior, se puede observar que las primeras 17 componentes explican, aproximadamente, el 80% de la variabilidad. Para confirmar esto analíticamente, se calcula la variabilidad acumulada de las componentes y se obtiene la mínima componente con un 80% aproximado de esta: 


```{r, echo=FALSE}
# Variabilidad acumulada
prop_expl_var <- cumsum((main_pca$sdev)^2)/sum((main_pca$sdev)^2)

# Número óptimo de componentes con, aproximadamente, un 80% de explicación de la variabilidad
npc_opt <- which.min(abs(prop_expl_var-0.8))
npc_opt
```
Lo cual confirma lo que se mostró anterior. Para ver gráficamente lo anterior: 

```{r, echo=FALSE,fig.cap = "Figura 1: Numero de CP que explican el 80% de variabilidad"}
plot(prop_expl_var,
     type = "h", las = 1, xlim = c(1,90),
     ylab = "Proporción de varianza explicada", xlab = "Numero Componentes",
     main = "Número óptimo de componentes principales")
points(npc_opt, prop_expl_var[npc_opt],
       col = "red", lwd = 2)

segments(x0 = 0 ,y0 = prop_expl_var[npc_opt],
         x1 = npc_opt, y1 = prop_expl_var[npc_opt],
         col = "red", lwd = 2)
segments(x0 = npc_opt, y0 = 0, x1 = npc_opt,
         y1 = prop_expl_var[npc_opt], col = "red", lwd = 2)
```

Como resumen de las componentes, el siguiente gráfico muestra la varianza explicada por la primeras 10 componentes: 

```{r, echo=FALSE, fig.cap = "Figura 2: Grafico de la varianza por CP"}
plot(main_pca, main = "Varianza por cada componente",xlab="Componentes Principales",las = 2, cex.names = 0.7)
```

## Reconstrucción del conjunto de datos

Se necesita tener la proyección del conjunto de datos sobre las componentes principales óptimas, para luego unirlo con el conjunto categórico. Esta proyección se realiza obteniendo los vectores propios de estas componentes, y aplicando un producto de matrices entre estos vectores y el conjunto de datos numéricos. Finalmente, se une este nuevo conjunto de datos con el categórico. 

```{r}
# Vectores propios
eigen <- main_pca$loadings[, 1:npc_opt]

# Valores proyectados en las componentes
df_proy <- df_num_scale%*%eigen

# Unión de la proyección con el conjunto categórico.
df_final <- cbind(as.data.frame(df_proy), df_fact_nocip)
df_final <- delete.na(df_final)


head(df_proy)
```

Ahora se muestra un gráfico de pares para las primeras 5 componentes del conjunto de datos:

```{r, fig.cap= "Figura 3: Grafico de dispersion de las 5 CP"}
pairs(df_proy[,1:5], main="Graficos de Dispersion CP")
```
De esto se puede concluir que no existe algún tipo de relación entre las componentes evaluadas ya que la información no sigue algún patrón de linealidad. 

# Agrupamiento de los datos

Se determina la cantidad óptima de clúster probando con diferentes valores de K y se evalúan con el Método de Codo (el cual calcula la suma del cuadrado de los errores para cada clúster). Para esto se hace uso del método *kproto*. 

```{r, fig.cap="Figura 4: Grafica de Codo para k optimo"}
# Elbow Method for finding the optimal number of clusters
set.seed(130622)

# Compute and plot wss for k = 2 to k = 15.
k.max <- 15

wss <- sapply(1:k.max,
              function(k){kproto(df_final, k, na.rm = FALSE)$tot.withinss})
plot(1:k.max, wss,
     type="b", pch = 19, frame = FALSE,
     xlab="Number of clusters K",
     ylab="Total within-clusters sum of squares")
```

Para la selección óptima de clústers se escogen dos K y, de la gráfica anterior, se compara cuál de estos da la mayor inclinación. En particular, se eligen 4 clústers ya que este es el que mejor muestra tal comportamiento. Luego, con este K óptimo, se construye el modelo de agrupamiento con el método KProto debido a que este permite el tratamiento de datos categóricos y numéricos a la vez. 

```{r, echo=FALSE}
set.seed(130622)

# Clúster para todos incluido los caracteristica
k_opt <- 4
clusters_final <- kproto(df_final, k_opt, na.rm = FALSE, verbose=FALSE)
```

Teniendo el agrupamiento, se proyectan las componentes 1 y 2 en este para observar cómo se distribuyen. Este es el resultado:

```{r, echo=FALSE, fig.cap= "Figura 5: Comp 1 vs Copm 2 discriminado por su respectivo cluster"}
df_final$clus <- as.factor(clusters_final$cluster)

plot(df_final$Comp.1, df_final$Comp.2, col=df_final$clus, 
     xlab="Componente Principal 1", 
     ylab="Componente Principal 2", 
     main = "Componente 1 vs Componente 2", 
     pch = c(15, 16, 17, 18, 19)[as.numeric(df_final$clus)])

legend("topleft", legend = paste("Cluster", 1:4), pch=c(15, 16, 17, 18, 19), col=1:4)
```

Adicionalmente, se puede calcular la importancia de cada variable en las componentes. Esto ayuda para la elección de los representantes de cada clúster. Esto se lleva todas las componentes y se hace uso del método *melt*:  

```{r, include=TRUE, cache=FALSE}
# Importancia de cada variable por componente
melted <- melt(main_pca$loadings[,1:npc_opt])

melted$value_abs<-abs(melted$value)
```
Se realiza el cálculo de la importancia por cada componente, luego se ordena de manera ascendente, se seleccionan las primeras cuatro variables de cada componente, y se eliminan las duplicadas.

```{r, echo=FALSE}
df_melted_sorted <- melted %>% group_by(melted$Var2) %>% arrange(Var2, desc(melted$value_abs)) %>% slice(1:4)
important_vars_name <- as.data.frame(unique(df_melted_sorted$Var1))
colnames(important_vars_name) = c("ImportantVars")
```

A continuación se presenta gráficamente la importancia de las variables para las primeras 3 componentes:

```{r}

melted_sort <- melted[order(melted$value_abs,decreasing = T),]

# Individualmente para ver cada variable

# Componente1
melted_sort1<-melted_sort %>%  filter(Var2=="Comp.1") %>% head(10)

ggplot(data = melted_sort1[melted_sort1$Var2 == "Comp.1",]) +
  theme(legend.position = "none", 
        axis.text.x= element_text(angle=45, hjust = 1), 
        axis.ticks.x = element_blank()) + 
  labs(x = "Variables ",
       y = "Relative importance in principle component",
       title = "Variables in PC1") +
  geom_bar(aes(x=reorder(Var1,-value_abs), y=value_abs, fill=Var1), stat="identity")


# Componente 2
melted_sort2<-melted_sort %>% filter(Var2=="Comp.2") %>% head(10)

ggplot(data = melted_sort2[melted_sort2$Var2 == "Comp.2",]) +
  theme(legend.position = "none", 
        axis.text.x= element_text(angle=45, hjust = 1), 
        axis.ticks.x = element_blank()) + 
  labs(x = "Variables ",
       y = "Relative importance in principle component",
       title = "Variables in PC2") +
  geom_bar(aes(x=reorder(Var1,-value_abs), y=value_abs, fill=Var1), stat="identity")

# Componente 3
melted_sort3<-melted_sort %>% filter(Var2=="Comp.3") %>% head(10)

ggplot(data = melted_sort3[melted_sort3$Var2 == "Comp.3",]) +
  theme(legend.position = "none", 
        axis.text.x= element_text(angle=45, hjust = 1), 
        axis.ticks.x = element_blank()) + 
  labs(x = "Variables ",
       y = "Relative importance in principle component",
       title = "Variables in PC3") +
  geom_bar(aes(x=reorder(Var1,-value_abs), y=value_abs, fill=Var1), stat="identity")

```

De manera general, en la componente 2 se observa que tanto las variables más importantes (DEBT_MDN, DEBT_MDN_SUPP, etc) como el resto tienen relación con deuda que tiene los estudiantes que aún estudian. Por ende, es un indicio que esta componente trata de describir la información relacionada con las deudas de los estudiantes actuales. Por otra parte, la componente 3 tiene también una relación con las deudas, sin embargo la información que contiene está asociada a los estudiantes ya graduados.

# Análisis sobre los clústers

Las variables con mayor importancia por componente se unen con las categóricas para realizar un análisis conjunto. A este, además, se le agrega una columna que especifica a qué clúster pertenece cada registro. Esta columna se utiliza para agrupar los registros por clúster y calcular la media y la mediana de cada variable en cada uno de los clústers.  
Se muestra el resumen de los datos con la métrica del promedio:

```{r, echo=F}
df_original_total <- df_num[,(colnames(df_num) %in% important_vars_name$ImportantVars)]
df_original_total$CLUSTER <- as.factor(clusters_final$cluster)


df_filter_mean <- df_original_total %>% group_by(CLUSTER) %>% summarise_all("mean")
df_filter_mean
```


Similarmente, el análisis con la mediana:

```{r, echo=F}
df_filter_median <- df_original_total %>% group_by(CLUSTER) %>% summarise_all("median")
kable(df_filter_median)
```


```{r, echo=F}
df_fact_nocip$CLUSTER <- as.factor(clusters_final$cluster)
clprofiles(clusters_final, df_fact_nocip)
```
De acuerdo a las gráficas anteriores se puede realizar un análisis para las siguientes variables:

* **Main**: esta variable especifica si el registro de una universidad es un campus principal. En este caso, se puede observar que la mayoría de las universidad que son un campus un principal se encuentran en los clústers 3 y 4. Además, la distrubución de los que no son principales es similar en los clústers 1 y 2. 
* **PREDDEG**: representa el grado predominante otorgado por una universidad. De su gráfica, se puede determinar que la mayoría de las universidades que tienen como grado predonominante los certificados se encuentran en el clúster 1. Además, gran parte de las universidades con grado predominante de títulos profesionales se encuentran en el clúster 3. Cabe destacar que en el clúster 2 y 4 se ubican las universidad con grados predominantes de técnicos. 
* **HIGHDEG**: representa el mayor grado que ofrece una universidad. En el clúster 1, en su mayoría, el mayor grado que ofrece una universidad son los certificados; mientras que en el clúster 4 son los grados técnicos. En el clúster 3 se ubican las universidades que ofrecen como mayor grado uno profesional. Finalmente, cabe resaltar que en el clúster 2 existe una distrubución similar de las cuatro categorías.
* **CONTROL**: especifica el tipo de universidad: pública, privada sin ánimo de lucro y privada con ánimo de lucro. De aquí se puede interpretar que las universidades que pertenecen al clúster 1 y 2, en su mayoría, son privadas con ánimo de lucro. Mientras que la mayoría que pertenecen al clúster 4 son públicas. Finalmente, en el clúster 3 se pueden encontrar una combinación de públicas y privadas sin ánimo de lucro. 

```{r}
centers <- clusters_final$centers[0:npc_opt]
mu = colMeans(df_num)
# calculamos los variables originales de los centros para cada cluster
center_recon = as.matrix(centers[,1:npc_opt]) %*% t(main_pca$loadings[, 1:npc_opt])
center_recon = as.data.frame(scale(center_recon, center = -mu, scale = FALSE))

cbind(center_recon, clusters_final$centers[(npc_opt+1):27])
```


# Agrupación de universidades en Colombia

El Sistema Nacional de Información de la Educación Superior (SNIES) se encarga de compilar y estructurar diferentes datos referentes a las diferentes instituciones de educación superior del país (IES) [4]. El objetivo de este sistema es generar información que permita orientar a las IES en la toma de decisiones que permitan mejorar la calidad del sistema educativo y generar también indicadores que permitan evaluarlas.

En las bases consolidadas del SNIES se pueden encontrar datos que permitan generar algún tipo de agrupamiento como el desarrollado en el presente documento, datos como:

- Estudiantes inscritos, admitidos, matriculados y graduados: Entre estos datos se encuentra información sobre la localidad y modalidad de la universidad y detalles sobre programa acádemico, distinguiendo la cantidad de hombres y mujeres por cada semestre desde el año 2013.
- Recuento de docentes que ejercieron cada semestre en las ies, ditinguiendo entre: sexo, formación, tiempo de dedicación y tipo de vínculación. 

En las consultas públicas se puede encontrar una base de datos con información sobre todas las ies oficiales del país con su localidad, sector, acreditacón y convenios, y de sus programas académicos se tiene el nivel, la modalidad y el reconocimiento del ministerio. [5]

Con estos datos se pueden generar algunos datos relevantes similares a los que se encontraron en el presente documento, como por ejemplo, tasas de admision, localidad, modalidad, campus principal, acreditación, nivel más alto, entre otros. También hay otros datos relevantes que no se han encontrado o no son de dominio público, por ejemplo, los créditos y becas otorgados a estudiantes, precio del programa y alumnos distinguiendo por etnia o condiciones físicas o mentales. Algunos de estos datos pueden ser encontrados en las encuestas de calidad de vida del DANE, pero es posible que no se tenga información de la ies asociada al encuestado. 


# Bibliografía

[1] G. James, *Et all*, *An Introduction to Statistical Learning with  Applications in R*. New York :Springer, 2013. [E-book].  
[2] Klaudia. Bury, 'Clustering on PCA results', 2021. [Online]. Available: https://rpubs.com/Bury/ClusteringOnPcaResults. [Accessed: 11- Jun- 2022]
[3] Luke. Hayden, 'Principal Component Analysis in R Tutorial ', 2018. [Online]. Available: https://www.datacamp.com/tutorial/pca-analysis-r. [Accessed: 09- Jun- 2022]
[4] Qué es el SNIES. Snies.mineducacion.gov.co. (2022). Retrieved 14 June 2022, from https://snies.mineducacion.gov.co/portal/EL-SNIES/Que-es-el-SNIES/.
[5] Información Poblacional - SNIES. Hecaa.mineducacion.gov.co. (2022). Retrieved 14 June 2022, from https://hecaa.mineducacion.gov.co/consultaspublicas/ies.