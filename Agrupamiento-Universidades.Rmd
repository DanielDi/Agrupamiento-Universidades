---
title: "Agrupamiento-Universidades"
author: "Brayan Ortiz, Juan Peña, Thalea Hesse, Juan Falcon, Daniel Espinal"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(convertr)
library(dplyr)
library(stringr)
library(factoextra)
library(zoo)
library(purrr)
library(Gifi)
```


# Lectura de datos

```{r, echo=FALSE}
datos <- read.csv("datos/CollegeScorecard.csv")
```

# Procesamiento de los datos

El conjunto de datos cuentas con 1725 características, sin embargo muchas de ellas no contienen información. Por esta razón se deciden eliminar las característica que tengan más del 20% en valores NaN. Por otra parte, el conjunto de datos contiene diferentes formas para representar los valores vacíos, por ejemplo cadenas de texto vacías o con espacios y, adicionalmente, hay registros con valores en *PrivacySuppressed*. Todos estos valores se recopilaron y se replazaron por el objeto NA de R.  

Existen variables (INSTNM, NPCURL, INSTURL) con todos los valores, pero no aportan información para el análisis. Estas columnas también fueron eliminadas del conjunto de datos.


```{r, echo=FALSE}
# Reemplazar algunos valores con NA
df <- replace(datos, datos=="PrivacySuppressed", NA) # revisar: parece que quedan como strings
df <- replace(df, df==" ", NA)
df <- replace(df, df=="", NA)

# Se borran columnas con valores nulos (>20%)
df <- df[,-which(colMeans(is.na(df)) >= 0.2)]

# Se borran filas con valores nulos
# delete.na <- function(df, n=0) {
#  df[rowSums(is.na(df)) <= n,]
# }
# df <- delete.na(df)

# Eliminar columnas manualmente
df <- subset(df, select = -c(INSTNM, NPCURL, INSTURL, UNITID, 
                             OPEID, opeid6))

# Algunas variables, a pesar de ser numéricas, tienen muy poca variabilidad: poolyrs
```

## Convertir los tipos de datos

```{r, echo=FALSE}
columnas <- data.frame(colnames(df))

columnas_CIP <- columnas %>% 
  filter(str_detect(colnames.df., "^CIP"))

df <- df %>% 
  mutate_at(vars(main, region, CONTROL, CURROPER, HCM2, LOCALE, DISTANCEONLY, STABBR, st_fips,
                 HBCU, PBI, ANNHI, TRIBAL, AANAPII, HSI, NANTI, MENONLY, WOMENONLY, PREDDEG, HIGHDEG,
                 CURROPER), 
            list(as.factor)) %>% 
  mutate_at(vars(columnas_CIP$colnames.df.), list(as.factor))

# st_fips se puede borrar y dejar solo region
```

```{r, echo=FALSE}
#Separar df por tipo de columna
# colSums(is.na(df)/7804)

#Convertir todos los chr a factor
df <- df %>% mutate(across(.cols=where(is.character), .fns=as.factor))

df_fact <- df[sapply(df, is.factor)] # Acá quedan variables numéricas (RARO xd)

index_i <- grep("CURROPER", colnames(df_fact))+1
index_s <- ncol(df_fact)

df_aux <- df_fact[c(index_i:index_s)]
df_fact <- df_fact[c(0:(index_i-1))]

df_aux <- mutate_all(df_aux, as.numeric)


df_num <- df %>% 
    select_if(is.numeric)

df_num <- cbind(df_num, df_aux)

# addNA para añadir NA como level del factor.
df_fact <- modify(df_fact, addNA)
#rowSums(is.na(df_fact))
```
 
## Interpolación de los datos faltantes
Los datos numéricos faltantes se completan realizando una extrapolación de los datos que se tienen en la base datos. Se hacen separado para los datos numéricos y enteros. 

```{r, echo=FALSE}
# Interpolación para los datos numéricos
df_num <- rapply(df_num, zoo::na.fill,"numeric",fill="extend",how="replace")

# Interpolacińo para los datos enteros
df_num <- rapply(df_num, zoo::na.fill,"integer",fill="extend",how="replace")

# Estandarización de los datos
df_num_scale <- scale(df_num, center = TRUE, scale = TRUE)
```

# Componentes principales

Se decide realizar componentes principales agrupando variables que hacen parte de la misma descripción en el diccionario de datos. En particular, se obtienen las componentes principales de las variables que empiecen por PCIP (de las cuales hay 38) y UGDS (con 10 variables).  

```{r, echo=FALSE}
cols_nums <- data.frame(colnames(df_num_scale))

# Obtiene el rango de columnas llamadas PCIP*
df_pcip <- cols_nums %>% 
  filter(str_detect(colnames.df_num_scale., "^PCIP"))

df_pcip <- subset(df_num_scale, select = df_pcip$colnames.df_num_scale.)

# Obtiene el rango de columnas llamadas UGDS*
df_ugds <- cols_nums %>% 
  filter(str_detect(colnames.df_num_scale., "^UGDS"))

df_ugds <- subset(df_num_scale, select = df_ugds$colnames.df_num_scale.)
```

Las variables PCIP tienen el siguiente resumen de las componentes:  

```{r, echo=FALSE}
# Componentes principales para las variables PCIP*
pcip_cp <- princomp(df_pcip)
summary(pcip_cp)
```
De lo anterior, se puede observar que las primeras 25 componentes explican, aproximadamente, el 80% de la variabilidad. En el siguiente gráfico se muestra la varianza explicada por la primeras 10 componentes: 

```{r, echo=FALSE}
plot(pcip_cp, main = "Varianza por cada componente")
```

Para determinar la cantidad óptima de componentes con base a una explicación de la variabilidad del 80%, se calcula la variabilidad acumulada de las componentes y se obtiene la mínima componente con un 80% aproximado de esta: 

```{r, echo=FALSE}
# Variabilidda acumulada
prop_expl_var_pcip <- cumsum((pcip_cp$sdev)^2)/sum((pcip_cp$sdev)^2)

# Número óptimo de componentes con, aproximadamente, un 80% de explicación de la variabilidad
npc_opt_pcip <- which.min(abs(prop_expl_var_pcip-0.8))
npc_opt_pcip
```

Para ver gráficamente lo anterior: 

```{r, echo=FALSE}
plot(prop_expl_var_pcip,
     type = "h", las = 1, xlim = c(1,47),
     ylab = "Proporción de varianza explicada", xlab = "m", 
     main = "Número óptimo de componentes principales")
points(npc_opt_pcip, prop_expl_var_pcip[npc_opt_pcip], 
       col = "red", lwd = 2)

segments(x0 = 0 ,y0 = prop_expl_var_pcip[npc_opt_pcip],
         x1 = npc_opt_pcip, y1 = prop_expl_var_pcip[npc_opt_pcip],
         col = "red", lwd = 2)
segments(x0 = npc_opt_pcip, y0 = 0, x1 = npc_opt_pcip,
         y1 = prop_expl_var_pcip[npc_opt_pcip], col = "red", lwd = 2)
```

Análogamente, se hace un análisis de componentes principales para las variables UGDS.  

En el siguiente resumen, se puede determinar que con 7 componentes se alcanza a explicar el 80% de la variabilidad de los datos: 
```{r, echo=FALSE}
# Componentes principales para las variables UGDS*
ugds_cp <- princomp(df_ugds)
summary(ugds_cp)
```
El análisis análitico lo confirma: 

```{r, echo=FALSE}
# Variabilidda acumulada
prop_expl_var_ugds <- cumsum((ugds_cp$sdev)^2)/sum((ugds_cp$sdev)^2)

# Número óptimo de componentes con, aproximadamente, un 80% de explicación de la variabilidad
npc_opt_ugds <- which.min(abs(prop_expl_var_ugds-0.8))
npc_opt_ugds
```

# Componentes principales de los datos categóricos

```{r}
# Ejemplo: http://www.css.cornell.edu/faculty/dgr2/_static/files/R_html/NonlinearPCA.html
# pero no termina ... 
# cols_prin_fact <- princals(df_fact, ndim = 2, ordinal = FALSE, itmax=5)

```
Finalmente, se tiene la representación gráfica para lo anterior: 

```{r, echo=FALSE}
plot(prop_expl_var_ugds,
     type = "h", las = 1, xlim = c(1,47),
     ylab = "Proporción de varianza explicada", xlab = "m", 
     main = "Número óptimo de componentes principales")
points(npc_opt_ugds, prop_expl_var_ugds[npc_opt_ugds], 
       col = "red", lwd = 2)

segments(x0 = 0 ,y0 = prop_expl_var_ugds[npc_opt_ugds],
         x1 = npc_opt_ugds, y1 = prop_expl_var_ugds[npc_opt_ugds],
         col = "red", lwd = 2)
segments(x0 = npc_opt_ugds, y0 = 0, x1 = npc_opt_ugds,
         y1 = prop_expl_var_ugds[npc_opt_ugds], col = "red", lwd = 2)
```

## Proyección de los datos en las componentes

A continuación se representa cada conjunto de datos en sus componentes principales multiplicando por la cantidad óptima de vectore propios de cada conjunto. Estos vectores propios los devuelve el método *princomp*.  

A manera de resumen, se presenta los valores óptimos para cada conjunto de variables:  

* **PCIP**: `r npc_opt_pcip` componentes.  
* **UGDS**: `r npc_opt_ugds` componentes.  

En las variables PCIP se tienen las siguientes proyecciones:
```{r, echo=FALSE}
eigen_pcip <- pcip_cp$loadings[, 1:npc_opt_pcip]

# Valores de PCIP proyectados en las componentes
df_pcip_proy <- df_pcip%*%eigen_pcip
colnames(df_pcip_proy) <- paste(colnames(df_pcip_proy), "_PCIP", sep="")
head(df_pcip_proy)
```

Similarmente, se tiene para las variables UGDS:
```{r, echo=FALSE}
eigen_ugds <- ugds_cp$loadings[, 1:npc_opt_ugds]

# Valores de PCIP proyectados en las componentes
df_ugds_proy <- df_ugds%*%eigen_ugds
colnames(df_ugds_proy) <- paste(colnames(df_ugds_proy), "_UGDS", sep="")
head(df_ugds_proy)
```
## Reconstrucción del conjunto de datos

Como se calcularon las componentes para un subconjunto de variables, entonces es necesario unificar estos nuevos valores proyectados con las variables a las cuales no se les calculó componentes. Para esto, se eliminan del conjunto de datos las variables que fueron proyectadas y se añaden sus proyecciones, mientras que las demás variables permanencen iguales.

```{r, echo=FALSE}
# Elimina las columnas PCIP y UGDS
df_num_scale_completed <- df_num_scale[,!(colnames(df_num_scale) %in% colnames(df_pcip))]
df_num_scale_completed <- df_num_scale_completed[,!(colnames(df_num_scale_completed) %in% colnames(df_ugds))]

df_num_no_cp <- df_num_scale_completed
# Unifica las proyecciones con las variables que se tienen
df_num_scale_completed <- cbind(df_num_scale_completed, df_pcip_proy)
df_num_scale_completed <- cbind(df_num_scale_completed, df_ugds_proy)

```
Estas fueron las variables que quedaron en el conjunto de datos: 
```{r, echo=FALSE}
colnames(df_num_scale_completed)
```

# Modelo

```{r, echo=FALSE}
# Clúster para las UGDS
fviz_nbclust(ugds_cp$scores, FUNcluster=kmeans)
eclust(ugds_cp$scores, "kmeans", hc_metric="eucliden",k=2)
```
```{r, echo = FALSE}
# Clúster para las PCIP
fviz_nbclust(pcip_cp$scores, FUNcluster=kmeans)
eclust(pcip_cp$scores, "kmeans", hc_metric="eucliden",k=3)
```

```{r, echo = FALSE}
# Clúster para las variables sin componente
fviz_nbclust(df_num_no_cp, FUNcluster=kmeans)
eclust(df_num_no_cp, "kmeans", hc_metric="eucliden",k=2)
```

```{r, echo=FALSE}
# Cluśter de todo el conjunto de datos
km1<-eclust(df_num_scale_completed, "kmeans", hc_metric="eucliden",k=2)

```


