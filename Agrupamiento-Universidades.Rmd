---
title: "Agrupamiento-Universidades"
author: "Brayan Ortiz, Juan Peña, Thalea Hesse, Juan Falcon, Daniel Espinal"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(convertr)
library(dplyr)
library(stringr)
library(factoextra)
library(zoo)
```


# Lectura de datos

```{r, echo=FALSE}
datos <- read.csv("datos/CollegeScorecard.csv")
```

# Procesamiento de los datos

El conjunto de datos cuentas con 1725 características, sin embargo muchas de ellas no contienen información. Por esta razón se deciden eliminar las característica que tengan más del 20% en valores NaN. Por otra parte, el conjunto de datos contiene diferentes formas para representar los valores vacíos, por ejemplo cadenas de texto vacías o con espacios y, adicionalmente, hay registros con valores en *PrivacySuppressed*. Todos estos valores se recopilaron y se replazaron por el objeto NA de R.  

Existen variables (INSTNM, NPCURL, INSTURL) con todos los valores, pero no aportan información para el análisis. Estas columnas también fueron eliminadas del conjunto de datos.


```{r, echo=FALSE}
# Reemplazar algunos valores con NA
df <- replace(datos, datos=="PrivacySuppressed", NA) # revisar: parece que quedan como strings
df <- replace(df, df==" ", NA)
df <- replace(df, df=="", NA)

# Se borran columnas con valores nulos (>20%)
df <- df[,-which(colMeans(is.na(df)) >= 0.2)]

# Se borran filas con valores nulos
# delete.na <- function(df, n=0) {
#  df[rowSums(is.na(df)) <= n,]
# }
# df <- delete.na(df)

# Eliminar columnas manualmente
df <- subset(df, select = -c(INSTNM, NPCURL, INSTURL, UNITID, 
                             OPEID, opeid6))

# Algunas variables, a pesar de ser numéricas, tienen muy poca variabilidad: poolyrs
```

## Convertir los tipos de datos

```{r, echo=FALSE}
columnas <- data.frame(colnames(df))

columnas_CIP <- columnas %>% 
  filter(str_detect(colnames.df., "^CIP"))

df <- df %>% 
  mutate_at(vars(main, region, CONTROL, CURROPER, HCM2, LOCALE, DISTANCEONLY, STABBR, st_fips,
                 HBCU, PBI, ANNHI, TRIBAL, AANAPII, HSI, NANTI, MENONLY, WOMENONLY, PREDDEG, HIGHDEG,
                 CURROPER), 
            list(as.factor)) %>% 
  mutate_at(vars(columnas_CIP$colnames.df.), list(as.factor))

# st_fips se puede borrar y dejar solo region
```

```{r, echo=FALSE}
#Separar df por tipo de columna
# colSums(is.na(df)/7804)

#Convertir todos los chr a factor
df <- df %>% mutate(across(.cols=where(is.character), .fns=as.factor))

df_fact <- df[sapply(df, is.factor)] # Acá quedan variables numéricas (RARO xd)

index_i <- grep("CURROPER", colnames(df_fact))+1
index_s <- ncol(df_fact)

df_aux <- df_fact[c(index_i:index_s)]

df_aux <- mutate_all(df_aux, as.numeric)



df_num <- df %>% 
    select_if(is.numeric)

df_num <- cbind(df_num, df_aux)

#TODO
# addNA para añadir NA como level del factor.
# df <- modify(df, addNA)
```
 
## Interpolación de los datos faltantes
Los datos numéricos faltantes se completan realizando una extrapolación de los datos que se tienen en la base datos. Se hacen separado para los datos numéricos y enteros. 

```{r, echo=FALSE}
# Interpolación para los datos numéricos
df_num <- rapply(df_num, zoo::na.fill,"numeric",fill="extend",how="replace")

# Interpolacińo para los datos enteros
df_num <- rapply(df_num, zoo::na.fill,"integer",fill="extend",how="replace")

# Estandarización de los datos
df_num_scale <- scale(df_num, center = TRUE, scale = TRUE)
```

# Componentes principales

Se decide realizar componentes principales agrupando variables que hacen parte de la misma descripción en el diccionario de datos. En particular, se obtienen las componentes principales de las variables que empiecen por PCIP (de las cuales hay 38) y UGDS (con 10 variables).  

```{r, echo=FALSE}
cols_nums <- data.frame(colnames(df_num_scale))

# Obtiene el rango de columnas llamadas PCIP*
df_pcip <- cols_nums %>% 
  filter(str_detect(colnames.df_num_scale., "^PCIP"))

df_pcip <- subset(df_num_scale, select = df_pcip$colnames.df_num_scale.)

# Obtiene el rango de columnas llamadas UGDS*
df_ugds <- cols_nums %>% 
  filter(str_detect(colnames.df_num_scale., "^UGDS"))

df_ugds <- subset(df_num_scale, select = df_ugds$colnames.df_num_scale.)
```

Las variables PCIP tienen el siguiente resumen de las componentes:  

```{r, echo=FALSE}
# Componentes principales para las variables PCIP*
pcip_cp <- princomp(df_pcip)
summary(pcip_cp)
```
De lo anterior, se puede observar que las primeras 25 componentes explican, aproximadamente, el 80% de la variabilidad. En el siguiente gráfico se muestra la varianza explicada por la primeras 10 componentes: 

```{r, echo=FALSE}
plot(pcip_cp, main = "Varianza por cada componente")
```

Para determinar la cantidad óptima de componentes con base a una explicación de la variabilidad del 80%, se calcula la variabilidad acumulada de las componentes y se obtiene la mínima componente con un 80% aproximado de esta: 

```{r, echo=FALSE}
# Variabilidda acumulada
prop_expl_var_pcip <- cumsum((pcip_cp$sdev)^2)/sum((pcip_cp$sdev)^2)

# Número óptimo de componentes con, aproximadamente, un 80% de explicación de la variabilidad
npc_opt_pcip <- which.min(abs(prop_expl_var_pcip-0.8))
npc_opt_pcip
```

Para ver gráficamente lo anterior: 

```{r, echo=FALSE}
plot(prop_expl_var_pcip,
     type = "h", las = 1, xlim = c(1,47),
     ylab = "Proporción de varianza explicada", xlab = "m", 
     main = "Número óptimo de componentes principales")
points(npc_opt_pcip, prop_expl_var_pcip[npc_opt_pcip], 
       col = "red", lwd = 2)

segments(x0 = 0 ,y0 = prop_expl_var_pcip[npc_opt_pcip],
         x1 = npc_opt_pcip, y1 = prop_expl_var_pcip[npc_opt_pcip],
         col = "red", lwd = 2)
segments(x0 = npc_opt_pcip, y0 = 0, x1 = npc_opt_pcip,
         y1 = prop_expl_var_pcip[npc_opt_pcip], col = "red", lwd = 2)
```

Análogamente, se hace un análisis de componentes principales para las variables UGDS.  

En el siguiente resumen, se puede determinar que con 7 componentes se alcanza a explicar el 80% de la variabilidad de los datos: 
```{r, echo=FALSE}
# Componentes principales para las variables UGDS*
ugds_cp <- princomp(df_ugds)
summary(ugds_cp)
```
El análisis análitico lo confirma: 

```{r, echo=FALSE}
# Variabilidda acumulada
prop_expl_var_ugds <- cumsum((ugds_cp$sdev)^2)/sum((ugds_cp$sdev)^2)

# Número óptimo de componentes con, aproximadamente, un 80% de explicación de la variabilidad
npc_opt_ugds <- which.min(abs(prop_expl_var_ugds-0.8))
npc_opt_ugds
```
Finalmente, se tiene la representación gráfica para lo anterior: 

```{r, echo=FALSE}
plot(prop_expl_var_ugds,
     type = "h", las = 1, xlim = c(1,47),
     ylab = "Proporción de varianza explicada", xlab = "m", 
     main = "Número óptimo de componentes principales")
points(npc_opt_ugds, prop_expl_var_ugds[npc_opt_ugds], 
       col = "red", lwd = 2)

segments(x0 = 0 ,y0 = prop_expl_var_ugds[npc_opt_ugds],
         x1 = npc_opt_ugds, y1 = prop_expl_var_ugds[npc_opt_ugds],
         col = "red", lwd = 2)
segments(x0 = npc_opt_ugds, y0 = 0, x1 = npc_opt_ugds,
         y1 = prop_expl_var_ugds[npc_opt_ugds], col = "red", lwd = 2)
```


# Modelo

```{r, echo=FALSE}
```
